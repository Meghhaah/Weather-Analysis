{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddefd891",
   "metadata": {},
   "source": [
    "### **<u>DATA PREPROCESSING</u>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe576348",
   "metadata": {},
   "source": [
    "### ***1. Dataset Conversion from CSV to TSV***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74610267",
   "metadata": {},
   "source": [
    "This code imports the pandas library and defines a function to convert the two dataset CSV files into TSV files. It reads each CSV file into a pandas DataFrame, saves it as a TSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e15ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted temperature.csv to Temperature.tsv\n",
      "Converted BinSize.csv to Stations.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to convert CSV to TSV with custom output file names\n",
    "def convert_csv_to_tsv():\n",
    "    # Define the input CSV files and their corresponding output TSV file names\n",
    "    csv_files = {\n",
    "        'temperature.csv': 'Temperature.tsv',\n",
    "        'BinSize.csv': 'Stations.tsv'\n",
    "    }\n",
    "\n",
    "    # Iterate over the CSV files and convert them to TSV\n",
    "    for csv_file, tsv_file in csv_files.items():\n",
    "        try:\n",
    "            # Construct the full path to the CSV file\n",
    "            csv_path = os.path.join(os.getcwd(), csv_file)\n",
    "            \n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(csv_path)\n",
    "            \n",
    "            # Construct the full path to the TSV file\n",
    "            tsv_path = os.path.join(os.getcwd(), tsv_file)\n",
    "            \n",
    "            # Save the DataFrame as a TSV file\n",
    "            df.to_csv(tsv_path, sep='\\t', index=False)\n",
    "            print(f'Converted {csv_file} to {tsv_file}')\n",
    "            \n",
    "            # Optionally, read the TSV file back to verify\n",
    "            df_tsv = pd.read_csv(tsv_path, sep='\\t')\n",
    "        except FileNotFoundError:\n",
    "            print(f'Error: The file {csv_file} was not found.')\n",
    "        except Exception as e:\n",
    "            print(f'An error occurred while processing {csv_file}: {e}')\n",
    "\n",
    "# Call the function to perform the conversion\n",
    "convert_csv_to_tsv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1ed866",
   "metadata": {},
   "source": [
    "### Why TSV is Better:\n",
    "- TSV files use tab as a delimiter, reducing issues caused by commas in data fields.\n",
    "- TSV format is simpler and less prone to errors when fields contain commas, making it more robust for certain datasets.\n",
    "- TSV files are easy to parse, especially in Unix-based systems where tools like cut, awk, and sed are commonly used.\n",
    "- They ensure better data integrity when working with complex textual data compared to CSV files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55b5a4c",
   "metadata": {},
   "source": [
    "### ***2. Temperature Dataset Cleaning***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79976b84",
   "metadata": {},
   "source": [
    "This code below reflects modifications made to the original temperature dataset for Ann Arbor, Michigan. The result is a cleaned and organized dataset, saved as a new file, optimized for creating graphs and visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acf7cf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before any changes: 165085\n",
      "No dates were found in mm-dd-yyyy format.\n",
      "\n",
      "The following rows contain leap days (February 29th) and will be removed:\n",
      "                 ID       Date Element  Data_Value\n",
      "18712   USC00205563 2012-02-29    TMAX          39\n",
      "18716   USC00200842 2012-02-29    TMIN         -56\n",
      "18729   USC00205563 2012-02-29    TMIN          -6\n",
      "18730   USC00200842 2012-02-29    TMAX          61\n",
      "18812   USC00208080 2012-02-29    TMIN         -44\n",
      "...             ...        ...     ...         ...\n",
      "154086  USC00208972 2008-02-29    TMIN        -128\n",
      "154089  USC00208972 2008-02-29    TMAX         -39\n",
      "161046  USC00203712 2008-02-29    TMAX         -33\n",
      "161054  USC00203712 2008-02-29    TMIN        -111\n",
      "164153  USC00205050 2008-02-29    TMAX          22\n",
      "\n",
      "[83 rows x 4 columns]\n",
      "\n",
      "No leap days (February 29th) remain in the DataFrame.\n",
      "\n",
      "Number of rows after all changes: 165002\n",
      "\n",
      "Maximum temperature(°C) across all rows: 40.6\n",
      "Minimum temperature(°C) across all rows: -34.3\n",
      "\n",
      "The DataFrame is sorted by the 'Date' column in ascending order.\n",
      "\n",
      "First 5 rows of the sorted DataFrame:\n",
      "                ID       Date Element  Temperature(°C)\n",
      "18049  USW00014853 2005-01-01    TMAX              5.6\n",
      "35479  USC00201502 2005-01-01    TMIN             -3.9\n",
      "49823  USC00200228 2005-01-01    TMAX             15.0\n",
      "17153  USC00207320 2005-01-01    TMAX             15.0\n",
      "49827  USC00200228 2005-01-01    TMIN             -3.9\n",
      "\n",
      "The modified DataFrame has been saved as 'Temp_Cleaned.tsv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "from datetime import datetime\n",
    "\n",
    "# Ask the user for the input file path\n",
    "file_path = os.path.join(os.getcwd(), 'Temperature.tsv')\n",
    "\n",
    "# Load the .tsv file into a DataFrame\n",
    "try:\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path and try again.\")\n",
    "    exit()\n",
    "\n",
    "# Print the number of rows before any changes\n",
    "print(f\"Number of rows before any changes: {len(df)}\")\n",
    "\n",
    "# Function to check and convert dates from mm-dd-yyyy to dd-mm-yyyy\n",
    "def convert_date(date_str):\n",
    "    try:\n",
    "        # Try parsing the date in mm-dd-yyyy format\n",
    "        date_obj = datetime.strptime(date_str, '%m-%d-%Y')\n",
    "        # If successful, convert it to dd-mm-yyyy format\n",
    "        return date_obj.strftime('%d-%m-%Y')\n",
    "    except ValueError:\n",
    "        # If parsing fails, return the original date (it's not in mm-dd-yyyy format)\n",
    "        return date_str\n",
    "\n",
    "# Apply the conversion function to the 'Date' column\n",
    "df['Date'] = df['Date'].apply(convert_date)\n",
    "\n",
    "# Check if any dates were converted (i.e., originally in mm-dd-yyyy format)\n",
    "converted_dates = df[df['Date'].str.contains(r'\\d{2}-\\d{2}-\\d{4}')]\n",
    "if not converted_dates.empty:\n",
    "    print(\"The following dates were in mm-dd-yyyy format and have been converted to dd-mm-yyyy format:\")\n",
    "    print(converted_dates)\n",
    "else:\n",
    "    print(\"No dates were found in mm-dd-yyyy format.\")\n",
    "\n",
    "# Convert the 'Date' column to datetime format for proper sorting\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='mixed', dayfirst=True)\n",
    "\n",
    "# Clean up rows where the date is February 29th (leap days)\n",
    "leap_days = df[df['Date'].dt.strftime('%d-%m') == '29-02']\n",
    "if not leap_days.empty:\n",
    "    print(\"\\nThe following rows contain leap days (February 29th) and will be removed:\")\n",
    "    print(leap_days)\n",
    "    df = df[df['Date'].dt.strftime('%d-%m') != '29-02']\n",
    "else:\n",
    "    print(\"\\nNo leap days (February 29th) were found in the DataFrame.\")\n",
    "\n",
    "# Check if any leap days remain in the DataFrame\n",
    "remaining_leap_days = df[df['Date'].dt.strftime('%d-%m') == '29-02']\n",
    "if not remaining_leap_days.empty:\n",
    "    print(\"\\nWarning: The following leap days (February 29th) still exist in the DataFrame:\")\n",
    "    print(remaining_leap_days)\n",
    "else:\n",
    "    print(\"\\nNo leap days (February 29th) remain in the DataFrame.\")\n",
    "\n",
    "# Convert temperatures from tenths of degrees Celsius to degrees Celsius\n",
    "df['Data_Value'] = df['Data_Value'] / 10\n",
    "\n",
    "# Rename the 'Data_Value' column to 'temperature(°C)'\n",
    "df.rename(columns={'Data_Value': 'Temperature(°C)'}, inplace=True)\n",
    "\n",
    "# Print the number of rows after all changes\n",
    "print(f\"\\nNumber of rows after all changes: {len(df)}\")\n",
    "\n",
    "# Print the maximum and minimum values in the 'temperature(°C)' column\n",
    "max_temp = df['Temperature(°C)'].max()\n",
    "min_temp = df['Temperature(°C)'].min()\n",
    "print(f\"\\nMaximum temperature(°C) across all rows: {max_temp}\")\n",
    "print(f\"Minimum temperature(°C) across all rows: {min_temp}\")\n",
    "\n",
    "# Sort the DataFrame by the 'Date' column in ascending order\n",
    "df_sorted = df.sort_values(by='Date')\n",
    "\n",
    "# Check if the DataFrame is sorted by the 'Date' column\n",
    "is_sorted = df_sorted['Date'].is_monotonic_increasing\n",
    "\n",
    "# Print the result of the check\n",
    "if is_sorted:\n",
    "    print(\"\\nThe DataFrame is sorted by the 'Date' column in ascending order.\")\n",
    "else:\n",
    "    print(\"\\nThe DataFrame is NOT sorted by the 'Date' column.\")\n",
    "\n",
    "# Display the first 5 rows of the sorted DataFrame\n",
    "print(\"\\nFirst 5 rows of the sorted DataFrame:\")\n",
    "print(df_sorted.head())\n",
    "\n",
    "# Save the modified DataFrame to a new .tsv file\n",
    "output_file_path = 'Temp_Cleaned.tsv'\n",
    "df_sorted.to_csv(output_file_path, sep='\\t', index=False)\n",
    "print(f\"\\nThe modified DataFrame has been saved as '{output_file_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252abac7",
   "metadata": {},
   "source": [
    "#### Changes Made with Code Snippets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb75b3bf",
   "metadata": {},
   "source": [
    "**1. Date Format Conversion:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d58d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = df['Date'].apply(convert_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f605968",
   "metadata": {},
   "source": [
    "*This line applies a function that converts dates from `mm-dd-yyyy` to `dd-mm-yyyy`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5410e88",
   "metadata": {},
   "source": [
    "**2. Leap Day Removal:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38405d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Date'].dt.strftime('%d-%m') != '29-02']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1ea3e8",
   "metadata": {},
   "source": [
    "*Rows with February 29th are removed to avoid inconsistencies across different years.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ea2ff3",
   "metadata": {},
   "source": [
    "**3. Temperature Conversion:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5703ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Data_Value'] = df['Data_Value'] / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec41a7eb",
   "metadata": {},
   "source": [
    "*Temperature values are converted from tenths of degrees Celsius to degrees Celsius.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da47fd03",
   "metadata": {},
   "source": [
    "**4. Column Renaming:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e506b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Data_Value': 'Temperature(°C)'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3664c85d",
   "metadata": {},
   "source": [
    "*Renames the column for better understanding.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd45936",
   "metadata": {},
   "source": [
    "**5. Sorting:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094c4276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e400898",
   "metadata": {},
   "source": [
    "*Ensures the data is arranged in chronological order for better analysis*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f644c53",
   "metadata": {},
   "source": [
    "**6. File Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5466553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.to_csv('Temp_Cleaned.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcf04b7",
   "metadata": {},
   "source": [
    "*Saves the cleaned Temperature dataset as a new TSV file for future use.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec26906a",
   "metadata": {},
   "source": [
    "### ***3. Weather Station Dataset Cleaning***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abceb1b",
   "metadata": {},
   "source": [
    "This code below reflects modifications made to the original Weather stations dataset. The result is a cleaned and organized dataset, saved as a new file, optimized for creating graphs and visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56585264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of rows where ID exists in the second file: 24\n",
      "\n",
      "Number of stations within 100 km of Ann Arbor: 24\n",
      "\n",
      "The final filtered DataFrame has been saved as 'W-Stations_Cleaned.tsv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Ask the user for the path to the first .tsv file\n",
    "file_path_1 = os.path.join(os.getcwd(), 'Stations.tsv')\n",
    "\n",
    "# Load the first .tsv file into a DataFrame\n",
    "try:\n",
    "    df1 = pd.read_csv(file_path_1, sep='\\t')\n",
    "except FileNotFoundError:\n",
    "    print(\"First file not found. Please check the file path and try again.\")\n",
    "    exit()\n",
    "\n",
    "# Keep only the 1st, 2nd, 3rd, and 6th columns\n",
    "columns_to_keep = df1.columns[[0, 1, 2, 5]]  # Indices 0, 1, 2, and 5 correspond to 1st, 2nd, 3rd, and 6th columns\n",
    "df1_filtered = df1[columns_to_keep].copy()  # Explicitly create a copy to avoid the warning\n",
    "\n",
    "# Round the LATITUDE and LONGITUDE columns to 6 decimal places using .loc\n",
    "df1_filtered.loc[:, 'LATITUDE'] = df1_filtered['LATITUDE'].round(6)\n",
    "df1_filtered.loc[:, 'LONGITUDE'] = df1_filtered['LONGITUDE'].round(6)\n",
    "\n",
    "# Ask the user for the path to the second .tsv file\n",
    "file_path_2 = os.path.join(os.getcwd(), 'Temperature.tsv')\n",
    "\n",
    "# Load the second .tsv file into a DataFrame\n",
    "try:\n",
    "    df2 = pd.read_csv(file_path_2, sep='\\t')\n",
    "except FileNotFoundError:\n",
    "    print(\"Second file not found. Please check the file path and try again.\")\n",
    "    exit()\n",
    "\n",
    "# Filter the first DataFrame to keep only rows where the ID exists in the second DataFrame\n",
    "df1_filtered = df1_filtered[df1_filtered['ID'].isin(df2['ID'])]\n",
    "\n",
    "# Print the number of rows that match\n",
    "num_matching_rows = len(df1_filtered)\n",
    "print(f\"\\nNumber of rows where ID exists in the second file: {num_matching_rows}\")\n",
    "\n",
    "# Define Ann Arbor coordinates\n",
    "ann_arbor_coords = (42.2808, -83.7430)\n",
    "\n",
    "# Filter stations within 100 km of Ann Arbor\n",
    "df1_filtered = df1_filtered[\n",
    "    df1_filtered.apply(\n",
    "        lambda row: geodesic((row['LATITUDE'], row['LONGITUDE']), ann_arbor_coords).km <= 100,\n",
    "        axis=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Print the number of rows that satisfy the 100 km radius condition\n",
    "num_nearby_stations = len(df1_filtered)\n",
    "print(f\"\\nNumber of stations within 100 km of Ann Arbor: {num_nearby_stations}\")\n",
    "\n",
    "# Save the final filtered DataFrame to a new .tsv file\n",
    "output_file_path = 'W-Stations_Cleaned.tsv'\n",
    "df1_filtered.to_csv(output_file_path, sep='\\t', index=False)\n",
    "print(f\"\\nThe final filtered DataFrame has been saved as '{output_file_path}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ac3110",
   "metadata": {},
   "source": [
    "#### Changes Made with Code Snippets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8c6855",
   "metadata": {},
   "source": [
    "**1. Unnecessary data cleaning:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4245635",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = df1.columns[[0, 1, 2, 5]]\n",
    "df1_filtered = df1[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3153199",
   "metadata": {},
   "source": [
    "*Keeps only essential columns: `ID`, `LATITUDE`, `LONGITUDE`, and `NAME` for relevance and to reduce dataset size.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2e3f2b",
   "metadata": {},
   "source": [
    "**2. Numerical Consistency:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16329c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_filtered['LATITUDE'] = df1_filtered['LATITUDE'].round(6)\n",
    "df1_filtered['LONGITUDE'] = df1_filtered['LONGITUDE'].round(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8429813",
   "metadata": {},
   "source": [
    "*Rounds coordinates to 6 decimal places for consistency and precision.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc69fbd",
   "metadata": {},
   "source": [
    "**3. Filter Dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1383b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_2 = input(\"\\nEnter the path to your second .tsv file: \")\n",
    "df1_filtered = df1_filtered[df1_filtered['ID'].isin(df2['ID'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec23f46",
   "metadata": {},
   "source": [
    "*Asks for The temperature dataset file and filters the dataset to keep only weather stations present in the Temp_Cleaned.tsv dataset by matching `ID`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83694db",
   "metadata": {},
   "source": [
    "**4. Geospatial Filtering:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c0e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_arbor_coords = (42.2808, -83.7430)\n",
    "\n",
    "df1_filtered = df1_filtered[\n",
    "    df1_filtered.apply(\n",
    "        lambda row: geodesic((row['LATITUDE'], row['LONGITUDE']), ann_arbor_coords).km <= 100,\n",
    "        axis=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f6dd3b",
   "metadata": {},
   "source": [
    "*Calculates distances from Ann Arbor coordinates and filter stations within a 100 km radius.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95b6ff6",
   "metadata": {},
   "source": [
    "**4. File Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0cc91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_filtered.to_csv('W-Stations_Cleaned.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de37e277",
   "metadata": {},
   "source": [
    "*Saves the cleaned weather station dataset new TSV file for future use.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
